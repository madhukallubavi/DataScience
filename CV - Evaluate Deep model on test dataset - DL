We can now load the final model and evaluate it on the hold out test dataset. This is something
we might do if we were interested in presenting the performance of the chosen model to project
stakeholders. The model can be loaded via the load model() function. The complete example
of loading the saved model and evaluating it on the test dataset is listed below.

#Evaluate Deep model on test dataset
from keras.datasets import fashion_mnist
from keras.models import load_model
from keras.utils import to_categorical

#load train and test dataset
def load_dataset():
  #load dataset
  (trainX, trainY), (testX, testY) = fashion_mnist.load_data()
  #reshape dataset to have a single channel
  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
  testX = testX.reshape((testX.shape[0], 28, 28, 1))
  #one hot encode target values
  trainY = to_categorical(trainY)
  testY = to_categorical(testY)
  return trainX, trainY, testX, testY

#scale pixels
def prep_pixels(train, test):
  #convert from integers to floats
  train_norm = train.astype('float32')
  test_norm = test.astype('float32')
  #normalize to range 0-1
  train_norm = train_norm / 255.0
  test_norm = test_norm / 255.0
  #return normalized images
  return train_norm, test_norm

#run the test harness for evaluating a model
def run_test_harness():
  #load dataset
  trainX, trainY, testX, testY = load_dataset()
  #prepare pixel data
  trainX, testX = prep_pixels(trainX, testX)
  #load model
  model = load_model('final_model.h5')
  #evaluate model on test dataset
  _, acc = model.evaluate(testX, testY, verbose=0)
  print('> %.3f' % (acc * 100.0))

#entry point, run the test harness
run_test_harness()

Results:
> 90.950

Running the example loads the saved model and evaluates the model on the hold out test
dataset. The classification accuracy for the model on the test dataset is calculated and printed.

Note: Your specific results may vary given the stochastic nature of the learning algorithm.
Consider running the example a few times and compare the average performance.

In this case, we can see that the model achieved an accuracy of 90.950%, or just less than
10% classification error, which is not bad.

Note: Your specific results may vary given the stochastic nature of the learning algorithm.
Consider running the example a few times and compare the average performance.
