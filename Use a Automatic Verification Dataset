Use a Automatic Verification Dataset

Keras can separate a portion of training data into a validation dataset and evaluate the
performance of model on that validation dataset each epoch. We can do this by setting the
validation split argument on the fit() function to a percentage of the size of your training
dataset. For example, a reasonable value might be 0.2 or 0.33 for 20% or 33% of your training
data held back for validation. The example below demonstrates the use of using an automatic
validation dataset on the Pima Indians onset of diabetes dataset



#MLP with automatic validation set
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import pandas as pd

#fix random seed for reproducibility
np.random.seed(7)

#load diabetes dataset
data = pd.read_csv('diabetes.csv')
array = data.values

#split into input(X) and output(Y) variables
X = array[:,0:8]
Y = array[:,8]

#create model
model = Sequential()
model.add(Dense(12, input_dim=8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

#compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#fit model
model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)

# evaluate the model
scores = model.evaluate(X, Y)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))


Results:
Epoch 148/150
514/514 [==============================] - 0s 506us/step - loss: 5.8013 - acc: 0.6401 - val_loss: 5.2669 - val_acc: 0.6732
Epoch 149/150
514/514 [==============================] - 0s 529us/step - loss: 5.8013 - acc: 0.6401 - val_loss: 5.2669 - val_acc: 0.6732
Epoch 150/150
514/514 [==============================] - 0s 529us/step - loss: 5.8013 - acc: 0.6401 - val_loss: 5.2669 - val_acc: 0.6732
768/768 [==============================] - 0s 47us/step

acc: 65.10%

Running the example, we can see that the verbose output on each epoch shows the loss
and accuracy on both the training dataset and the validation dataset.
