We can make the use of a 1 × 1 filter concrete with some examples. Consider that we have
a convolutional neural network that expected color images input with the square shape of
256 × 256 × 3 pixels. These images then pass through a first hidden layer with 512 filters, each
with the size of 3 × 3 with the same padding, followed by a ReLU activation function. The
example below demonstrates this simple model.

#Simple 1x1 CNN model
from keras.models import Sequential
from keras.layers import Conv2D

#create model
model = Sequential()
model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))

#summarize model
model.summary()

Results:
W0625 11:47:23.485040 140247680984960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0625 11:47:23.498899 140247680984960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 256, 256, 512)     14336     
=================================================================
Total params: 14,336
Trainable params: 14,336
Non-trainable params: 0
_________________________________________________________________

Running the example creates the model and summarizes the model architecture. There
are no surprises; the output of the first hidden layer is a block of feature maps with the
three-dimensional shape of 256 × 256 × 512
