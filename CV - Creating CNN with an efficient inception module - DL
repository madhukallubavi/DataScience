If you intend to use many inception modules in your model, you may require this compu-
tational performance-based modification. The function below implements this optimization
improvement with parameterization so that you can control the amount of reduction in the
number of filters prior to the 3 × 3 and 5 × 5 convolutional layers and the number of increased
filters after max pooling.

We can create a model with two of these optimized inception modules to get a concrete idea
of how the architecture looks in practice. In this case, the number of filter configurations are
based on inception (3a) and inception (3b) from Table 1 in the paper. The complete example is
listed below.

#Creating CNN with an efficient inception module
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D
from keras.layers.merge import concatenate
from keras.utils import plot_model

#function for creating a projected inception module
def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):
  #1x1 conv
  conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)
  #3x3 conv
  conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)
  conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)
  #5x5 conv
  conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)
  conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)
  #3x3 max pooling
  pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)
  pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)
  #concatenate filters, assumes filters/channels last
  layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)
  return layer_out

#define model input
visible = Input(shape=(256, 256, 3))
#add inception block 1
layer = inception_module(visible, 64, 96, 128, 16, 32, 32)
#add inception block 1
layer = inception_module(layer, 128, 128, 192, 32, 96, 64)

#create model
model = Model(inputs=visible, outputs=layer)

#summarize model
model.summary()

#plot model architecture
plot_model(model, show_shapes=True, to_file='inception_module.png')

Results:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 256, 256, 3)  0                                            
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 256, 256, 96) 384         input_10[0][0]                   
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 256, 256, 16) 64          input_10[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_12 (MaxPooling2D) (None, 256, 256, 3)  0           input_10[0][0]                   
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 256, 256, 64) 256         input_10[0][0]                   
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 256, 256, 128 110720      conv2d_27[0][0]                  
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 256, 256, 32) 12832       conv2d_29[0][0]                  
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 256, 256, 32) 128         max_pooling2d_12[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_26[0][0]                  
                                                                 conv2d_28[0][0]                  
                                                                 conv2d_30[0][0]                  
                                                                 conv2d_31[0][0]                  
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 256, 256, 128 32896       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 256, 256, 32) 8224        concatenate_2[0][0]              
__________________________________________________________________________________________________
max_pooling2d_13 (MaxPooling2D) (None, 256, 256, 256 0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 256, 256, 128 32896       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 256, 256, 192 221376      conv2d_33[0][0]                  
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 256, 256, 96) 76896       conv2d_35[0][0]                  
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 256, 256, 64) 16448       max_pooling2d_13[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256, 256, 480 0           conv2d_32[0][0]                  
                                                                 conv2d_34[0][0]                  
                                                                 conv2d_36[0][0]                  
                                                                 conv2d_37[0][0]                  
==================================================================================================
Total params: 513,120
Trainable params: 513,120
Non-trainable params: 0
__________________________________________________________________________________________________

Running the example creates a linear summary of the layers that does not really help to
understand what is going on. The output is omitted here for brevity. A plot of the model
architecture is created that does make the layout of each module clear and how the first model
feeds the second module. Note that the first 1 × 1 convolution in each inception module is on
the far right for space reasons, but besides that, the other layers are organized left to right
within each module.
