We can use some or all of the layers in a pre-trained model as a feature extraction component
of a new model directly. This can be achieved by loading the model, then simply adding new
layers. This may involve adding new convolutional and pooling layers to expand upon the
feature extraction capabilities of the model or adding new fully connected classifier type layers
to learn how to interpret the extracted features on a new dataset, or some combination. For
example, we can load the VGG16 models without the classifier part of the model by specifying
the include top argument to False, and specify the preferred shape of the images in our new
dataset as 300 Ã— 300.

We can then use the Keras functional API to add a new Flatten layer after the last pooling
layer in the VGG16 model, then define a new classifier model with a Dense fully connected
layer and an output layer that will predict the probability for 10 classes.

An alternative approach to adding a Flatten layer would be to define the VGG16 model
with an average pooling layer, and then add fully connected layers. Perhaps try both approaches
on your application and see which results in the best performance. The weights of the VGG16
model and the weights for the new model will all be trained together on the new dataset. The
complete example is listed below.

#Example of tending VGG16 model
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense, Flatten

#load model without classifier layers
model = VGG16(include_top=False, input_shape=(300, 300, 3))

#add new classifier layers
flat1 = Flatten()(model.outputs)
class1 = Dense(1024, activation='relu')(flat1)
output = Dense(10, activation='softmax')(class1)

#define new model
model = Model(inputs=model.inputs, outputs=output)

#summarize model
model.summary()

Results:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 300, 300, 3)       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 41472)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 1024)              42468352  
_________________________________________________________________
dense_4 (Dense)              (None, 10)                10250     
=================================================================
Total params: 57,193,290
Trainable params: 57,193,290
Non-trainable params: 0
_________________________________________________________________

Running the example defines the new model ready for training and summarizes the model
architecture. We can see that we have flattened the output of the last pooling layer and added
our new fully connected layers.
