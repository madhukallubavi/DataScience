The reduction in the size of the input to the feature map is referred to as border effects.
It is caused by the interaction of the filter with the border of the image. This is often not a
problem for large images and small filters but can be a problem with small images. It can also
become a problem once a number of convolutional layers are stacked. For example, below is the
same model updated to have two stacked convolutional layers. This means that a 3 × 3 filter is
applied to the 8 × 8 input image to result in a 6 × 6 feature map as in the previous section. A
3 × 3 filter is then applied to the 6 × 6 feature map.

#Stacked convolutional layers
from keras.models import Sequential
from keras.layers import Conv2D

# create model
model = Sequential()
model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))
model.add(Conv2D(1, (3,3)))

#summarize model
model.summary()

Results:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 6, 6, 1)           10        
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 1)           10        
=================================================================
Total params: 20
Trainable params: 20
Non-trainable params: 0

Running the example summarizes the shape of the output from each layer. We can see that
the application of filters to the feature map output of the first layer, in turn, results in a 4 × 4
feature map. This can become a problem as we develop very deep convolutional neural network
models with tens or hundreds of layers. We will simply run out of data in our feature maps
upon which to operate.
