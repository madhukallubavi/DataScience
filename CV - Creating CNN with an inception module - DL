To use the function, provide the reference to the prior layer as input, the number of filters,
and it will return a reference to the concatenated filters layer that you can then connect to more
inception modules or a submodel for making a prediction. We can demonstrate how to use this
function by creating a model with a single inception module. In this case, the number of filters
is based on inception (3a) from Table 1 in the paper. The complete example is listed below.

#Creating CNN with an inception module
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D
from keras.layers.merge import concatenate
from keras.utils import plot_model

#function for creating a naive inception block
def naive_inception_module(layer_in, f1, f2, f3):
  #1x1 conv
  conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)
  #3x3 conv
  conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)
  #5x5 conv
  conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)
  #3x3 max pooling
  pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)
  #concatenate filters, assumes filters/channels last
  layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)
  return layer_out

#define model input
visible = Input(shape=(256, 256, 3))
#add inception module
layer = naive_inception_module(visible, 64, 128, 32)

#create model
model = Model(inputs=visible, outputs=layer)

#summarize model
model.summary()

#plot model architecture
plot_model(model, show_shapes=True, to_file='naive_inception_module.png')

Results:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 256, 256, 3)  0                                            
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 256, 256, 64) 256         input_9[0][0]                    
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 256, 256, 128 3584        input_9[0][0]                    
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 256, 256, 32) 2432        input_9[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_11 (MaxPooling2D) (None, 256, 256, 3)  0           input_9[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 256, 256, 227 0           conv2d_23[0][0]                  
                                                                 conv2d_24[0][0]                  
                                                                 conv2d_25[0][0]                  
                                                                 max_pooling2d_11[0][0]           
==================================================================================================
Total params: 6,272
Trainable params: 6,272
Non-trainable params: 0
__________________________________________________________________________________________________

Running the example creates the model and summarizes the layers. We know the con-
volutional and pooling layers are parallel, but this summary does not capture the structure
easily.
